{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17d20bd5-43ee-4490-8811-6edbde5f86d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"MIG-864c07c4-8eeb-5b23-8d57-eaeb942a9a0f\"\n",
    "from hydra.utils import instantiate\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b6a10b-38a9-4fc5-8dd0-03babdccee70",
   "metadata": {},
   "source": [
    "# Load data and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f05f5c60-cae8-41d7-9297-eef048e459b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/allen/aics/modeling/ritvik/projects/benchmarking_representations/')\n",
    "save_path = './test_polymorphic_save_embeddings/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e130624-5f63-434f-8f5e-6d65404d5309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from br.data.get_datamodules import get_data\n",
    "from cyto_dl.models.utils.mlflow import load_model_from_checkpoint\n",
    "from br.models.load_models import load_model_from_path\n",
    "from br.models.save_embeddings import get_pc_loss\n",
    "\n",
    "def get_data_and_models(dataset_name, batch_size, results_path, debug=False):\n",
    "    data_list = get_data(dataset_name, batch_size, results_path, debug)\n",
    "    all_models, run_names, model_sizes = load_model_from_path(dataset_name, results_path) # default list of models in load_models.py\n",
    "    return data_list, all_models, run_names, model_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad792311-00e9-45ad-99b3-a3784a6b60e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_name = 'other_polymorphic'\n",
    "batch_size = 2\n",
    "debug=True\n",
    "results_path = '/allen/aics/modeling/ritvik/projects/benchmarking_representations/configs/results/'\n",
    "data_list, all_models, run_names, model_sizes = get_data_and_models(dataset_name, batch_size, results_path, debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3ee8d91-eeb3-4a99-8237-2a4f26456b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['equiv_vn',\n",
       " 'CNN_SO3_pad35_sdf',\n",
       " 'CNN_SO3_pad35_seg',\n",
       " 'CNN_sdf_pad35',\n",
       " 'CNN_seg_pad35']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb523c3-ef58-4557-8a31-e1eb095c95de",
   "metadata": {},
   "source": [
    "# Compute embeddings and emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7088001f-97ae-4091-a591-3aad744c7ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latent_dim': 512, 'spatial_dims': 3, 'in_shape': [1, 35, 35, 35], 'channels': [8, 16, 32, 64, 128, 256, 512], 'strides': [1, 1, 2, 2, 2, 2, 2], 'last_act': None, 'x_label': 'image', 'id_label': None, 'reconstruction_loss': MSELoss(), 'prior': None, 'embedding_prior': 'identity', 'group': 'so3', 'beta': 0, 'act': 'relu', 'norm': 'batch', 'dropout': None, 'bias': True, 'mask_input': True, 'mask_output': True, 'optimizer': functools.partial(<class 'torch.optim.adam.Adam'>, lr=0.001), 'background_value': 2, 'kernel_sizes': [3, 3, 3, 3, 3, 3, 3], 'encoder_padding': [None, None, None, None, None, None, None], 'first_conv_padding_mode': 'replicate', 'num_res_units': 2, 'num_dec_res_units': 0, 'decoder_channels': [512, 256, 128, 64, 32, 16], 'decoder_strides': [2, 2, 2, 2, 1, 1]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from br.models.save_embeddings import save_embeddings\n",
    "\n",
    "splits_list = [\"train\", 'val', \"test\"]\n",
    "meta_key = None\n",
    "eval_scaled_img = [True] * 5\n",
    "eval_scaled_img_params = [\n",
    "                        {\"eval_scaled_img_model_type\":\"iae\",\n",
    "                          \"eval_scaled_img_resolution\":32,\n",
    "                          \"gt_mesh_dir\":gt_mesh_dir,\n",
    "                          \"gt_scale_factor_dict_path\":None,\n",
    "                          \"gt_sampled_pts_dir\":gt_sampled_pts_dir,\n",
    "                          \"mesh_ext\":\"stl\"},\n",
    "                        {\"eval_scaled_img_model_type\":\"sdf\",\n",
    "                          \"eval_scaled_img_resolution\":32,\n",
    "                          \"gt_mesh_dir\":gt_mesh_dir,\n",
    "                          \"gt_scale_factor_dict_path\":gt_scale_factor_dict_path,\n",
    "                          \"gt_sampled_pts_dir\":None,\n",
    "                          \"mesh_ext\":\"stl\"},\n",
    "                        {\"eval_scaled_img_model_type\":\"seg\",\n",
    "                          \"eval_scaled_img_resolution\":32,\n",
    "                          \"gt_mesh_dir\":gt_mesh_dir,\n",
    "                          \"gt_scale_factor_dict_path\":gt_scale_factor_dict_path,\n",
    "                          \"gt_sampled_pts_dir\":None,\n",
    "                          \"mesh_ext\":\"stl\"},\n",
    "                        {\"eval_scaled_img_model_type\":\"sdf\",\n",
    "                          \"eval_scaled_img_resolution\":32,\n",
    "                          \"gt_mesh_dir\":gt_mesh_dir,\n",
    "                          \"gt_scale_factor_dict_path\":gt_scale_factor_dict_path,\n",
    "                          \"gt_sampled_pts_dir\":None,\n",
    "                          \"mesh_ext\":\"stl\"},\n",
    "                        {\"eval_scaled_img_model_type\":\"seg\",\n",
    "                          \"eval_scaled_img_resolution\":32,\n",
    "                          \"gt_mesh_dir\":gt_mesh_dir,\n",
    "                          \"gt_scale_factor_dict_path\":gt_scale_factor_dict_path,\n",
    "                          \"gt_sampled_pts_dir\":None,\n",
    "                          \"mesh_ext\":\"stl\"},]\n",
    "loss_eval_list = [torch.nn.MSELoss(reduction='none')]\n",
    "sample_points_list = [False]*5\n",
    "skew_scale = None\n",
    "save_embeddings(\n",
    "    save_path,\n",
    "    data_list,\n",
    "    all_models,\n",
    "    run_names,\n",
    "    debug,\n",
    "    splits_list,\n",
    "    device,\n",
    "    meta_key,\n",
    "    loss_eval_list,\n",
    "    sample_points_list,\n",
    "    skew_scale,\n",
    "    eval_scaled_img,\n",
    "    eval_scaled_img_params,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
