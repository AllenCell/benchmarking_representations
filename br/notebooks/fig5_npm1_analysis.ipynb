{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22c4a2e8-f280-463d-9140-68d0a8f8e63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"MIG-864c07c4-8eeb-5b23-8d57-eaeb942a9a0f\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from hydra.utils import instantiate\n",
    "from PIL import Image\n",
    "from sklearn.manifold import TSNE\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10394787-c363-4803-80ce-2f72ce16df21",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/allen/aics/modeling/ritvik/projects/benchmarking_representations/\")\n",
    "save_path = \"./test_npm1_save_embeddings/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3efaf167-6983-4d1d-9f51-0054830089e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cyto_dl.models.utils.mlflow import load_model_from_checkpoint\n",
    "\n",
    "from br.data.get_datamodules import get_data\n",
    "from br.models.load_models import load_model_from_path\n",
    "from br.models.save_embeddings import get_pc_loss\n",
    "\n",
    "\n",
    "def get_data_and_models(dataset_name, batch_size, results_path, debug=False):\n",
    "    data_list = get_data(dataset_name, batch_size, results_path, debug)\n",
    "    all_models, run_names, model_sizes = load_model_from_path(\n",
    "        dataset_name, results_path\n",
    "    )  # default list of models in load_models.py\n",
    "    return data_list, all_models, run_names, model_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac2b6072-3314-420b-9746-f67b28fb8539",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"npm1\"\n",
    "batch_size = 2\n",
    "debug = True\n",
    "results_path = (\n",
    "    \"/allen/aics/modeling/ritvik/projects/benchmarking_representations/br/configs/results/\"\n",
    ")\n",
    "data_list, all_models, run_names, model_sizes = get_data_and_models(\n",
    "    dataset_name, batch_size, results_path, debug\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7428170f-624a-4f9c-84b4-0c6162a2759a",
   "metadata": {},
   "source": [
    "# Compute embeddings and emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ac9560f-d9e6-4e3f-8af3-0651ba8f9056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SO3_pointcloud_SDF',\n",
       " 'SO3_image_SDF',\n",
       " 'SO3_image_seg',\n",
       " 'Classical_image_SDF',\n",
       " 'Classical_image_seg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc65e52e-0dbd-4651-bf92-e29d774ed2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                             | 4/4267 [00:11<3:17:21,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                        | 0/754 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m sample_points_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     44\u001b[0m skew_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m \u001b[43msave_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mall_models\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplits_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeta_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_eval_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_points_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskew_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_scaled_img\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_scaled_img_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/allen/aics/modeling/ritvik/projects/benchmarking_representations/br/models/save_embeddings.py:237\u001b[0m, in \u001b[0;36msave_embeddings\u001b[0;34m(save_folder, data_list, all_models, run_names, debug, split_list, device, meta_key, loss_eval_list, sample_points_list, skew_scale, eval_scaled_img, eval_scaled_img_params)\u001b[0m\n\u001b[1;32m    229\u001b[0m loss_eval \u001b[38;5;241m=\u001b[39m get_pc_loss() \u001b[38;5;28;01mif\u001b[39;00m loss_eval_list \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m loss_eval_list[j_ind]\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    231\u001b[0m     (\n\u001b[1;32m    232\u001b[0m         all_embeds,\n\u001b[1;32m    233\u001b[0m         all_data_ids,\n\u001b[1;32m    234\u001b[0m         all_splits,\n\u001b[1;32m    235\u001b[0m         all_loss,\n\u001b[1;32m    236\u001b[0m         all_metadata,\n\u001b[0;32m--> 237\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthis_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrack_emissions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43memissions_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mall_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mall_data_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mall_splits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mall_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mall_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeta_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthis_use_sample_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskew_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_scaled_img\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj_ind\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_scaled_img_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj_ind\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m     all_splits \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m all_splits \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m xs]\n\u001b[1;32m    259\u001b[0m     all_data_ids \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m all_data_ids \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m xs]\n",
      "File \u001b[0;32m/allen/aics/modeling/ritvik/projects/benchmarking_representations/br/models/save_embeddings.py:147\u001b[0m, in \u001b[0;36mcompute_embeddings\u001b[0;34m(model, this_data, split_list, loss_eval, track_emissions, emissions_path, all_embeds, all_data_ids, all_splits, all_loss, all_metadata, debug, device, meta_key, use_sample_points, skew_scale, sdf_forward_pass, sdf_process)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m split_list:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing val\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    141\u001b[0m     (\n\u001b[1;32m    142\u001b[0m         all_embeds,\n\u001b[1;32m    143\u001b[0m         all_data_ids,\n\u001b[1;32m    144\u001b[0m         all_splits,\n\u001b[1;32m    145\u001b[0m         all_loss,\n\u001b[1;32m    146\u001b[0m         all_metadata,\n\u001b[0;32m--> 147\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_dataloader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthis_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrack_emissions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43memissions_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mall_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mall_data_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mall_splits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mall_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mall_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeta_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_sample_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskew_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43msdf_forward_pass\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43msdf_process\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m split_list:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing test\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/allen/aics/modeling/ritvik/projects/benchmarking_representations/br/models/save_embeddings.py:69\u001b[0m, in \u001b[0;36mprocess_dataloader\u001b[0;34m(dataloader, model, loss_eval, track_emissions, emissions_path, split, all_embeds, all_data_ids, all_splits, all_loss, all_metadata, debug, device, meta_key, use_sample_points, skew_scale, sdf_forward_pass, sdf_process)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (debug) \u001b[38;5;129;01mand\u001b[39;00m j \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     (\n\u001b[1;32m     64\u001b[0m         all_embeds,\n\u001b[1;32m     65\u001b[0m         all_data_ids,\n\u001b[1;32m     66\u001b[0m         all_splits,\n\u001b[1;32m     67\u001b[0m         all_loss,\n\u001b[1;32m     68\u001b[0m         all_metadata,\n\u001b[0;32m---> 69\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_batch_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mall_splits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mall_data_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mall_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mall_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mall_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrack_emissions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43memissions_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeta_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_sample_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskew_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43msdf_forward_pass\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43msdf_process\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_embeds, all_data_ids, all_splits, all_loss, all_metadata\n",
      "File \u001b[0;32m/allen/aics/modeling/ritvik/projects/benchmarking_representations/br/models/predict_model.py:519\u001b[0m, in \u001b[0;36mprocess_batch_embeddings\u001b[0;34m(model, this_loss, device, i, all_splits, all_data_ids, all_embeds, all_loss, all_metadata, split, track, emissions_path, meta_key, use_sample_points, skew_scale, eval_scaled_img, eval_scaled_img_params)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 519\u001b[0m model_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrack_emissions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43memissions_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43memissions_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_sample_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_sample_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskew_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskew_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_scaled_img\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_scaled_img\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_scaled_img_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_scaled_img_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    532\u001b[0m i \u001b[38;5;241m=\u001b[39m remove(i)\n\u001b[1;32m    533\u001b[0m emissions_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n",
      "File \u001b[0;32m/allen/aics/modeling/ritvik/projects/benchmarking_representations/br/models/predict_model.py:415\u001b[0m, in \u001b[0;36mmodel_pass\u001b[0;34m(batch, model, device, this_loss, track_emissions, emissions_path, use_sample_points, skew_scale, eval_scaled_img, eval_scaled_img_params)\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mae_forward(\n\u001b[1;32m    405\u001b[0m         model,\n\u001b[1;32m    406\u001b[0m         batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpcloud\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    412\u001b[0m         emissions_csv,\n\u001b[1;32m    413\u001b[0m     )\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthis_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrack_emissions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtracker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43memissions_csv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_sample_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskew_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_scaled_img\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meval_scaled_img_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/allen/aics/modeling/ritvik/projects/benchmarking_representations/br/models/predict_model.py:332\u001b[0m, in \u001b[0;36mbase_forward\u001b[0;34m(model, batch, device, this_loss, track_emissions, tracker, end, emissions_csv, use_sample_points, skew_scale, eval_scaled_img, eval_scaled_img_model_type, eval_scaled_img_resolution, gt_mesh_dir, gt_sampled_pts_dir, gt_scale_factor_dict_path, mesh_ext)\u001b[0m\n\u001b[1;32m    318\u001b[0m     args \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    319\u001b[0m         (\n\u001b[1;32m    320\u001b[0m             cellid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m cellid, recon_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(cellids, recon_data_list)\n\u001b[1;32m    330\u001b[0m     ]\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m--> 332\u001b[0m         errs \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmulti_proc_scale_img_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m     loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(errs)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m track_emissions:\n",
      "File \u001b[0;32m~/anaconda3/envs/replearn/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/replearn/lib/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/replearn/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/replearn/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/anaconda3/envs/replearn/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from br.models.save_embeddings import save_embeddings\n",
    "\n",
    "splits_list = [\"train\", 'val', \"test\"]\n",
    "meta_key = None\n",
    "eval_scaled_img = [True] * 5\n",
    "\n",
    "gt_mesh_dir = \"/allen/aics/assay-dev/users/Alex/replearn/rep_paper/data/var_blobby_noalign/meshes\"\n",
    "gt_sampled_pts_dir = \"/allen/aics/assay-dev/users/Alex/replearn/rep_paper/data/sampled_pcs/npm1_var_noalign_global/1_res/0\"\n",
    "gt_scale_factor_dict_path = \"/allen/aics/assay-dev/users/Alex/replearn/rep_paper/data/npm1_var_scale_factor_32res_noalign_global.npz\"\n",
    "\n",
    "eval_scaled_img_params = [\n",
    "                        {\"eval_scaled_img_model_type\":\"iae\",\n",
    "                          \"eval_scaled_img_resolution\":32,\n",
    "                          \"gt_mesh_dir\":gt_mesh_dir,\n",
    "                          \"gt_scale_factor_dict_path\":None,\n",
    "                          \"gt_sampled_pts_dir\":gt_sampled_pts_dir,\n",
    "                          \"mesh_ext\":\"stl\"},\n",
    "                        {\"eval_scaled_img_model_type\":\"sdf\",\n",
    "                          \"eval_scaled_img_resolution\":32,\n",
    "                          \"gt_mesh_dir\":gt_mesh_dir,\n",
    "                          \"gt_scale_factor_dict_path\":gt_scale_factor_dict_path,\n",
    "                          \"gt_sampled_pts_dir\":None,\n",
    "                          \"mesh_ext\":\"stl\"},\n",
    "                        {\"eval_scaled_img_model_type\":\"seg\",\n",
    "                          \"eval_scaled_img_resolution\":32,\n",
    "                          \"gt_mesh_dir\":gt_mesh_dir,\n",
    "                          \"gt_scale_factor_dict_path\":gt_scale_factor_dict_path,\n",
    "                          \"gt_sampled_pts_dir\":None,\n",
    "                          \"mesh_ext\":\"stl\"},\n",
    "                        {\"eval_scaled_img_model_type\":\"sdf\",\n",
    "                          \"eval_scaled_img_resolution\":32,\n",
    "                          \"gt_mesh_dir\":gt_mesh_dir,\n",
    "                          \"gt_scale_factor_dict_path\":gt_scale_factor_dict_path,\n",
    "                          \"gt_sampled_pts_dir\":None,\n",
    "                          \"mesh_ext\":\"stl\"},\n",
    "                        {\"eval_scaled_img_model_type\":\"seg\",\n",
    "                          \"eval_scaled_img_resolution\":32,\n",
    "                          \"gt_mesh_dir\":gt_mesh_dir,\n",
    "                          \"gt_scale_factor_dict_path\":gt_scale_factor_dict_path,\n",
    "                          \"gt_sampled_pts_dir\":None,\n",
    "                          \"mesh_ext\":\"stl\"},]\n",
    "loss_eval_list = [torch.nn.MSELoss(reduction='none')]\n",
    "sample_points_list = [False]*5\n",
    "skew_scale = None\n",
    "save_embeddings(\n",
    "    save_path,\n",
    "    data_list,\n",
    "    all_models,\n",
    "    run_names,\n",
    "    debug,\n",
    "    splits_list,\n",
    "    device,\n",
    "    meta_key,\n",
    "    loss_eval_list,\n",
    "    sample_points_list,\n",
    "    skew_scale,\n",
    "    eval_scaled_img,\n",
    "    eval_scaled_img_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c2f79f-eec0-4037-a956-ea809b70fb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = 'npm1_test'\n",
    "run_names = [\"equiv_vnn\"]\n",
    "from src.models.compute_features import get_embeddings\n",
    "\n",
    "all_ret, df = get_embeddings(run_names, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f2f4ef-e253-418b-8b48-314038795fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/allen/aics/assay-dev/users/Alex/replearn/rep_paper/data/var_npm1_manifest.csv\")\n",
    "cols_to_use = df.columns.difference(all_ret.columns).tolist() + [\"CellId\"]\n",
    "all_ret = all_ret.merge(df[cols_to_use], on=\"CellId\")\n",
    "mesh_df = pd.read_csv(\n",
    "    \"/allen/aics/assay-dev/users/Alex/replearn/rep_paper/data/var_npm1_manifest.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710ae297-5c42-4769-83a8-dee160889f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_feat_df = pd.read_csv(\n",
    "    \"/allen/aics/assay-dev/users/Alex/replearn/rep_paper/processing_data/npm1_fullres_features.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e630c4-d8ff-4e61-9c10-94ab705854bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vals = []\n",
    "for ind, row in updated_feat_df.iterrows():\n",
    "    if row[\"connectivity_cc\"] >= 5.0:\n",
    "        new_val = \">=5\"\n",
    "    else:\n",
    "        new_val = str(row[\"connectivity_cc\"])\n",
    "    all_vals.append(new_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3013d12-3f19-4ce4-b920-ddc53fa07303",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_feat_df[\"new_connectivity_thresh\"] = all_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e967d146-c5af-4a33-992a-6be22fbf8019",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd3e5b0-76e4-445f-8a6f-1c1f2cacbe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ret = all_ret.merge(updated_feat_df[[\"CellId\", \"new_connectivity_thresh\"]], on=\"CellId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529fd913-5a43-4c83-a757-3e2be3e68ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ret[\"new_connectivity_thresh\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c190996-f991-4a57-9a24-bb044c1250bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.classification import get_classification_df\n",
    "\n",
    "connect_class = get_classification_df(all_ret, \"new_connectivity_thresh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b37186-eb3c-4637-a45a-8af8121cfedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regress_cols = ['avg_dists', 'std_dists', 'mean_volume',\n",
    "#                                            'std_volume', 'mean_surface_area', 'std_surface_area']\n",
    "cols = [\"avg_dists\"]\n",
    "all_ret = all_ret.drop(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fa1f43-c95b-4d3e-aa02-253586145649",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ret = all_ret.merge(updated_feat_df[[\"CellId\"] + regress_cols], on=\"CellId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e3fbe0-ac0e-41df-8f9c-68e77aa58214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.regression import get_regression_df\n",
    "\n",
    "regress = get_regression_df(all_ret, regress_cols, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cfa1d1-bda6-4cb2-b85b-bd42a82e08b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "regress.groupby([\"target\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd72a676-2239-4467-a713-203ecf5a1dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regress.to_csv('./npm1_global/regression.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dad28e1-9fa7-4f55-93a8-689fd9920c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "from cyto_dl.image.transforms import RotationMask\n",
    "from skimage.io import imread\n",
    "from sklearn.decomposition import PCA\n",
    "from src.data.utils import mesh_seg_model_output\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_pieces = \">=5\"\n",
    "\n",
    "for num_pieces in [\"1.0\", \"2.0\", \"3.0\", \"4.0\", \">=5\"]:\n",
    "    # num_pieces = '4.0'\n",
    "    this_sub_m = all_ret.loc[all_ret[\"new_connectivity_thresh\"] == num_pieces].reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "    all_features = this_sub_m[[i for i in this_sub_m.columns if \"mu\" in i]].values\n",
    "    latent_dim = 512\n",
    "    dim_size = latent_dim\n",
    "    x_label = \"pcloud\"\n",
    "    pca = PCA(n_components=dim_size)\n",
    "    pca_features = pca.fit_transform(all_features)\n",
    "    pca_std_list = pca_features.std(axis=0)\n",
    "    rank = 0\n",
    "    all_xhat = []\n",
    "    all_closest_real = []\n",
    "    all_closest_img = []\n",
    "    latent_walk_range = [-2, 0, 2]\n",
    "    # latent_walk_range = [-2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2]\n",
    "    for value_index, value in enumerate(tqdm(latent_walk_range, total=len(latent_walk_range))):\n",
    "        z_inf = torch.zeros(1, dim_size)\n",
    "        z_inf[:, rank] += value * pca_std_list[rank]\n",
    "        z_inf = pca.inverse_transform(z_inf)\n",
    "\n",
    "        dist = (all_features - z_inf) ** 2\n",
    "        dist = np.sum(dist, axis=1)\n",
    "        closest_idx = np.argmin(dist)\n",
    "        closest_real_id = this_sub_m.iloc[closest_idx][\"CellId\"]\n",
    "        mesh = pv.read(\n",
    "            mesh_df.loc[mesh_df[\"CellId\"] == closest_real_id][\"mesh_path_noalign\"].iloc[0]\n",
    "        )\n",
    "        mesh.save(f\"./npm1_global/closest2/{num_pieces}_{rank}_{value_index}.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb0d62d-c9ae-4b59-99cb-7c1116d30b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_ret = all_ret\n",
    "matrix = this_ret[[i for i in this_ret.columns if \"mu\" in i]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc4c065-6c4d-449a-83be-5d8be68fb90b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b81045-a416-4ed9-b2a6-125de16a48c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.archetype import AA_Fast\n",
    "\n",
    "n_archetypes = 5\n",
    "aa = AA_Fast(n_archetypes, max_iter=1000, tol=1e-6).fit(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e103de1-1855-48f7-8d8a-6bf58eedd606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "archetypes_df = pd.DataFrame(aa.Z, columns=[f\"mu_{i}\" for i in range(matrix.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ff7d2d-b4e1-4f04-96b2-ed4122e11ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "archetypes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc64c1b-5d37-4084-b9cc-7168154c71e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = matrix\n",
    "for i in range(n_archetypes):\n",
    "    this_mu = archetypes_df.iloc[i].values\n",
    "    dist = (all_features - this_mu) ** 2\n",
    "    dist = np.sum(dist, axis=1)\n",
    "    closest_idx = np.argmin(dist)\n",
    "    closest_real_id = this_ret.iloc[closest_idx][\"CellId\"]\n",
    "    print(dist, closest_real_id)\n",
    "    mesh = pv.read(mesh_df.loc[mesh_df[\"CellId\"] == closest_real_id][\"mesh_path_noalign\"].iloc[0])\n",
    "    mesh.save(f\"./npm1_global/archetype2/{i}.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6be272-2be7-4eea-ad75-2d577ee43cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3442de-7499-43b9-b4ab-501cb40de257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_features =  matrix\n",
    "# for i in range(n_archetypes):\n",
    "#     this_mu = archetypes_df.iloc[i].values\n",
    "#     dist = (all_features - this_mu) ** 2\n",
    "#     dist = np.sum(dist, axis=1)\n",
    "#     closest_idx = np.argmin(dist)\n",
    "#     closest_real_id = this_ret.iloc[closest_idx]['CellId']\n",
    "#     print(dist, closest_real_id)\n",
    "#     mesh = pv.read(mesh_df.loc[mesh_df['CellId'] == closest_real_id]['mesh_path_noalign'].iloc[0])\n",
    "#     mesh.save(f'./npm1_test/closest/archetype/{i}.ply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d701912-2160-4ee9-8568-c695442aaea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ret[\"STR_connectivity_cc_thresh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d69b509-4927-4b7a-981a-4a7b62e09cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hh in all_ret[\"new_connectivity_thresh\"].unique():\n",
    "    this_ret = all_ret.loc[all_ret[\"new_connectivity_thresh\"] == hh].reset_index(drop=True)\n",
    "    labels = this_ret[\"structure_name\"].values\n",
    "    # labels = this_ret['cell_stage_fine'].values\n",
    "    matrix = this_ret[[i for i in this_ret.columns if \"mu\" in i]].values\n",
    "    from src.features.archetype import AA_Fast\n",
    "\n",
    "    n_archetypes = 3\n",
    "    aa = AA_Fast(n_archetypes, max_iter=1000, tol=1e-6).fit(matrix)\n",
    "    all_features = matrix\n",
    "    for i in range(n_archetypes):\n",
    "        print(hh, i)\n",
    "        this_mu = archetypes_df.iloc[i].values\n",
    "        dist = (all_features - this_mu) ** 2\n",
    "        dist = np.sum(dist, axis=1)\n",
    "        closest_idx = np.argmin(dist)\n",
    "        closest_real_id = this_ret.iloc[closest_idx][\"CellId\"]\n",
    "        print(dist, closest_real_id)\n",
    "        mesh = pv.read(\n",
    "            mesh_df.loc[mesh_df[\"CellId\"] == closest_real_id][\"mesh_path_noalign\"].iloc[0]\n",
    "        )\n",
    "        mesh.save(f\"./npm1_global/archetype/per_piece/{hh}_{i}_{closest_real_id}.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f379965-c469-44a8-9c6c-ad0134219671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "\n",
    "img = imread(all_ret.loc[all_ret[\"CellId\"] == 974872][\"crop_seg_masked\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d3b79e-2330-416c-a3a7-e633b840153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ret[\"volume_of_nucleus_um3\"] = all_ret[\"NUC_shape_volume_lcc\"] * 0.108**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ae0461-9d5e-470c-addb-0f466a4b4eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [(370.839, 577.444], (577.444, 784.05], (163.2, 370.839], (784.05, 990.656],  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9a11df-292c-41e7-b148-450dce451bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ret[\"volume_of_nucleus_um3\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8842dd-e4c9-4693-910d-4969028186c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ret[\"outlier\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437d2b75-1195-4099-beb4-8f7a33aa3e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in all_ret.columns if \"outlier\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f568516c-5880-4b73-be4f-7ed9493e7f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = \"volume_of_nucleus_um3\"\n",
    "upper = np.quantile(all_ret[feat], q=0.975)\n",
    "lower = np.quantile(all_ret[feat], q=0.025)\n",
    "\n",
    "this = all_ret.loc[all_ret[feat] < upper]\n",
    "this = this.loc[this[feat] > lower].reset_index(drop=True)\n",
    "# this = all_ret\n",
    "\n",
    "# this = this.loc[this['CellId'] != 956566].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c3325f-9366-4e73-b31a-ccafcf70d8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "this[feat].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611680fb-4e29-472b-9928-5bb167e40fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "this[\"vol_bins\"] = pd.cut(this[feat], bins=5)\n",
    "this[\"vol_bins_ind\"] = pd.factorize(this[\"vol_bins\"])[0]\n",
    "\n",
    "# this['vol_bins'] = pd.qcut(this[feat], q=5)\n",
    "# this['vol_bins_ind'] = pd.factorize(this['vol_bins'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ea2d4d-f8ca-418c-a60b-895f8025f49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "this[\"vol_bins\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cea2b4-7173-4a4e-8b5e-ed0ec582f331",
   "metadata": {},
   "outputs": [],
   "source": [
    "this[\"vol_bins_ind\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced5b373-e867-42b0-93af-672ffec9f080",
   "metadata": {},
   "outputs": [],
   "source": [
    "this[\"vol_bins_ind\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2a4624-0897-487f-aaf7-8abc340c5f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "this[\"vol_bins\"].astype(str).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0d368c-03a3-4bc9-852a-139979dccc6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902efbe4-9ebe-4241-a485-0ebf605bb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = this[[i for i in this.columns if \"mu\" in i]].values\n",
    "this[\"vol_bins\"] = this[\"vol_bins\"].astype(str)\n",
    "for hh in this[\"vol_bins\"].unique():\n",
    "    this_ret = this.loc[this[\"vol_bins\"] == hh].reset_index(drop=True)\n",
    "\n",
    "    this_mu = np.expand_dims(\n",
    "        this_ret[[i for i in this_ret.columns if \"mu\" in i]].mean(axis=0), axis=0\n",
    "    )\n",
    "    dist = (all_features - this_mu) ** 2\n",
    "    # dist = np.sum(dist, axis=1)\n",
    "    k = 2\n",
    "    # print(min(latent_dim, all_features.shape[0]))\n",
    "    inds = np.argpartition(dist.sum(axis=-1), k)[:k]  # get 10 closest\n",
    "    closest_samples = this.iloc[inds].reset_index(drop=True)\n",
    "    for ind, row in closest_samples.iterrows():\n",
    "        # closest_real_id = this.iloc[closest_idx]['CellId']\n",
    "        closest_real_id = row[\"CellId\"]\n",
    "        print(\n",
    "            closest_idx,\n",
    "            this_ret[\"vol_bins\"].unique(),\n",
    "            all_features.shape,\n",
    "            this_ret.shape,\n",
    "            this_ret[\"NUC_shape_volume_lcc\"].mean(),\n",
    "            closest_real_id,\n",
    "        )\n",
    "        mesh = pv.read(\n",
    "            mesh_df.loc[mesh_df[\"CellId\"] == closest_real_id][\"mesh_path_noalign\"].iloc[0]\n",
    "        )\n",
    "        mesh.save(f\"./npm1_global/vol_bin2/{hh}_{ind}_{closest_real_id}.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001d0493-0fce-421e-991a-60b5ba833b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37019b32-5a8f-4ca2-951e-7ebb399a31d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce5710d-eb6f-40c1-b874-59bca029ec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e928040-117f-44e6-b2c8-6bfc6ed3614d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
